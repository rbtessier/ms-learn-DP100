{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Real-time inferencing & Deployment\n",
    "\n",
    "[More info on HOw and when to deploy](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli) - includes info on which compute target to choose\n",
    "\n",
    "In machine learning, *Inferencing* refers to the use of a trained model to predict labels for new data on which the model has not been trained. Often, the model is deployed as part of a service that enables applications to request immediate, or *real-time*, predictions for individual or small numbers of data observations.\n",
    "\n",
    "In Azure ML, you can create real-time inferencing solutions by deploying a model as a service, hosted in a containerized platform such as Azure Kubernetes Services (AKS).\n",
    "\n",
    "## Learning objectives\n",
    "In this module, you will learn how to:\n",
    "- Deploy a model as a real-time inferencing service.\n",
    "- Consume a real-time inferencing service.\n",
    "- Troubleshoot service deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks to deploying a real-time inferencing service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Register a trained model\n",
    "After successful training, you must register it in your Azure Machine Learning workspace. THe real- time service will then be able to load the model when required. Use the `register` method of the `Model` object as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "classification_model = Model.register(workspace=ws,\n",
    "                                      model_name = 'classification_model',\n",
    "                                      model_path='modelpkl', # local path\n",
    "                                      description = 'A classification model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you have a reference to the `Run` used to train the model, you can use it `register_model` method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.register_model( model_name='classification_model',\n",
    "                    model_path='outputs/model.pkl', # run outputs path\n",
    "                    description='A classification model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define an Inference COnfiguration\n",
    "The model will be deployed as a service that consists of\n",
    "- a script to load the model and return predictions for submitted data\n",
    "- an environment in which the script will be run\n",
    "You must therefore define the script and environment.\n",
    "### Steps\n",
    "1. Create an *entry script*( or *scoring script*) -The entry script receives data submitted to a deployed web service and passes it to the model. It then takes the response returned by the model and returns that to the client. The script is specific to your model. It must understand the data that the model expects and returns. must be a .py file and requires\n",
    "  - `init()`: called when service initialized, loads model from model registry\n",
    "  - `run(raw_data)`: called when new data is submitted to the service. generate prediction from the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the registered model file and load it\n",
    "    model_path = Model.get_model_path('classification_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Return the predictions as any JSON serializable format\n",
    "    return predictions.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creating an environment - easy way to do this is use a `CondaDependencies` class to create a default environment (which includes the `azureml-defaults` package and commonly-used packages like `numpy` and `pandas`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4903fc951e2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconda_dependencies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCondaDependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Add the dependencies for your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmyenv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCondaDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmyenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_conda_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"scikit-learn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentrypoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_entry_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRUN_TYPE_PROVIDERS_ENTRYPOINT_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mRun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_type_provider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentrypoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         module_logger.warning(\"Failure while loading {}. Failed to load entrypoint {} with exception {}.\".format(\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, require, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrequire\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2462\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2466\u001b[0m         \u001b[0mResolve\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentry\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mits\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \"\"\"\n\u001b[1;32m-> 2468\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__name__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\train\\automl\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Suppress the warnings at the import phase.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautomlconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoMLConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\train\\automl\\automlconfig.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRunConfiguration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataprep_utilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_utilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_utilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_check_validation_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\automl\\core\\dataprep_utilities.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mDATAPREP_INSTALLED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataprep\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdprep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mDATAPREP_INSTALLED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\dataprep\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Dataflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataflowReference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReplacementsValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHistogramArgumentsValue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mKernelDensityArgumentsValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSummaryColumnsValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSummaryFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJoinType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\dataprep\\api\\dataflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minspector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_Inspector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_InspectorBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseInspector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_pandas_helper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhave_pandas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhave_pyarrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpyarrow_and_pandas_compatible\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPandasImportError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdatasources\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSSQLDataSource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPostgreSQLDataSource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLocalDataSource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFileOutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataDestination\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFileDataSource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mreferences\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_activity_reference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExternalReference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_to_anonymous_reference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m from .step import (Step, steps_to_block_datas, single_column_to_selector_value, MultiColumnSelection,\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\dataprep\\api\\datasources.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFileOutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m     \"\"\"\n\u001b[0;32m    281\u001b[0m     \u001b[0mBase\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0many\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\dataprep\\api\\datasources.py\u001b[0m in \u001b[0;36mFileOutput\u001b[1;34m()\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mfile_output_from_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'FileOutput'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m    289\u001b[0m         \u001b[0mConstructs\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mBlobFileOutput\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mLocalFileOutput\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mprovided\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Add the dependencies for your model\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = 'service_files/env.yml'\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Combining the Script and Environment in an InferenceConfig - An inference configuration describes how to set up the web-service containing your model. It's used later, when you deploy the model.Inference configuration uses Azure Machine Learning environments to define the software dependencies needed for your deployment. Environments allow you to create, manage, and reuse the software dependencies required for training and deployment.  you can combine the entry script and environment in an `InferenceConfig` for the service like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - source directory C:\\Users\\psych\\Jupyter Projects\\ms-learn-DP100\\service_files doesn't exist. \n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: source directory C:\\Users\\psych\\Jupyter Projects\\ms-learn-DP100\\service_files doesn't exist. \n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"source directory C:\\\\Users\\\\psych\\\\Jupyter Projects\\\\ms-learn-DP100\\\\service_files doesn't exist. \"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b9991323bfae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInferenceConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m classifier_inference_config = InferenceConfig(runtime= \"python\",\n\u001b[0m\u001b[0;32m      4\u001b[0m                                               \u001b[0msource_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'service_files'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                               \u001b[0mentry_script\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"score.py\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\core\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, entry_script, runtime, conda_file, extra_docker_file_steps, source_directory, enable_gpu, description, base_image, base_image_registry, cuda_version, environment)\u001b[0m\n\u001b[0;32m   2085\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2087\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2089\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\core\\model.py\u001b[0m in \u001b[0;36mvalidate_configuration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2190\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2191\u001b[1;33m             \u001b[0mvalidate_path_exists_or_throw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"source directory\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2193\u001b[0m         validate_path_exists_or_throw(joinPath(self.source_directory, self.entry_script),\n",
      "\u001b[1;32mc:\\users\\psych\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\azureml\\_model_management\\_util.py\u001b[0m in \u001b[0;36mvalidate_path_exists_or_throw\u001b[1;34m(member, name, extra_message)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_path_exists_or_throw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_message\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         raise WebserviceException(\"{0} {1} doesn't exist. {2}\".format(name, member, extra_message),\n\u001b[0m\u001b[0;32m    876\u001b[0m                                   logger=module_logger)\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: source directory C:\\Users\\psych\\Jupyter Projects\\ms-learn-DP100\\service_files doesn't exist. \n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"source directory C:\\\\Users\\\\psych\\\\Jupyter Projects\\\\ms-learn-DP100\\\\service_files doesn't exist. \"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                              source_directory = 'service_files',\n",
    "                                              entry_script=\"score.py\",\n",
    "                                              conda_file=\"env.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Deployment Configuration\n",
    "\n",
    "With entry script and environment defined, now configure the compute to which service will be deployed. If you don't have one, you must create an AKS (or ACI if testing and dev) cluster and compute target before deploying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "cluster_name = 'aks-cluster'\n",
    "compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
    "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With compute target created, now you can define the deployment config, whcih sets the target-specific compute specification for the containerized deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure ACI deployment is similar, but you don't need to explicity create an ACI compute target and you must use the `deploy_configuration` class from the `azureml.core.webservice.AciWebservice` namespace. Similarly you can use the `azureml.core.webservice.LocalWebservice` namespace to configure a local Docker-based service.\n",
    "\n",
    "`note`: To deploy a model to an Azure FUnction, you do not need to create a deployment configuration. Instead you need to package the model based on the type of function trigger you want to use. This functionality is still in preview as of `august 15 2020`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Deploy the model - easiest way after all this prep is to call the `deploy` method of the `Model` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['classification_model']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'classifier-service',\n",
    "                       models = [model],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = production_cluster)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOr ACI or local services, you can omit the `deployment_target` parameter (or set to `none`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming a Real-time inferencing service\n",
    "\n",
    "### Using Azure ML SDK\n",
    "\n",
    "FOr testing, use this through the `run` method of a `WebService` object that rerefences the deployed service. Typically you send data to the `run` method in JSON format with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"data\":[\n",
    "      [0.1,2.3,4.1,2.0], // 1st case\n",
    "      [0.2,1.8,3.9,2.1],  // 2nd case,\n",
    "      ...\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe following calls the service and displays a resonse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[0.1,2.3,4.1,2.0],\n",
    "         [0.2,1.8,3.9,2.1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "response = service.run(input_data = json_data)\n",
    "\n",
    "# Get the predictions\n",
    "predictions = json.loads(response)\n",
    "\n",
    "# Print the predicted class for each case.\n",
    "for i in range(len(x_new)):\n",
    "    print (x_new[i]), predictions[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a REST Endpoint\n",
    "In production, most client applications will not include the Azure Machine Learning SDK, and will consume the service through its REST interface. YOu can determine the endpoint of a deployed service in Azure machine learning studio, or by retriving the `scoring_uri` property of th e`Webservice` object in the SDK like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With endpoint known, you can use an HTTP POST request with JSON data to call the service, the following is an example in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[0.1,2.3,4.1,2.0],\n",
    "         [0.2,1.8,3.9,2.1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type in the request headers\n",
    "request_headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "# Call the service\n",
    "response = requests.post(url = endpoint,\n",
    "                         data = json_data,\n",
    "                         headers = request_headers)\n",
    "\n",
    "# Get the predictions from the JSON response\n",
    "predictions = json.loads(response.json())\n",
    "\n",
    "# Print the predicted class for each case.\n",
    "for i in range(len(x_new)):\n",
    "    print (x_new[i]), predictions[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "In production, you'll want to restrict access to your services by applying authentication. Two kinds:\n",
    "- **Key**: Requests are authenticated by specifying the key associated with the service.\n",
    "- **Token**: Requests are authenticated by providing a JSON Web Token (JWT)\n",
    "\n",
    "Authentication is **disabled** by default for ACI services, and set to key-based authentication for AKS services (for which primary and secondary keys are automatically generated). YOu can configure AKS to use token based (ACI doesn't support token based)\n",
    "\n",
    "Once authenticated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key, secondary_key = service.get_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO make an authenticated call to the service's REST endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[0.1,2.3,4.1,2.0],\n",
    "         [0.2,1.8,3.9,2.1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type in the request headers\n",
    "request_headers = { \"Content-Type\":\"application/json\",\n",
    "                    \"Authorization\":\"Bearer \" + key_or_token }\n",
    "\n",
    "# Call the service\n",
    "response = requests.post(url = endpoint,\n",
    "                         data = json_data,\n",
    "                         headers = request_headers)\n",
    "\n",
    "# Get the predictions from the JSON response\n",
    "predictions = json.loads(response.json())\n",
    "\n",
    "# Print the predicted class for each case.\n",
    "for i in range(len(x_new)):\n",
    "    print (x_new[i]), predictions[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Service Deployment\n",
    "Lots of elements to a real-time service deployment, including the trained model, the runtime environment configuration, the scoring script, the container image, and the container host. Troubleshooting a failed deployment, or an error when consuming a deployed service can be complex.\n",
    "\n",
    "Here are some things that can be done to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check the Service State\n",
    "As an initial step, check status of service by examining its **state**. Below we show it for the ACI webservice, but for AKS you can use `AksWebservice`. FOr an operational service, the state should be Healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "# Get the deployed service\n",
    "service = AciWebservice(name='classifier-service', workspace=ws)\n",
    "\n",
    "# Check its state\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Review Service Logs\n",
    "If service not healthy, or experiencing errors, review logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs include detailed information about the provisioning of the service, and the requests it has processed; and can often provide an insight into the cause of unexpected errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to a Local Container\n",
    "Deployment and runtime errors can be easier to diagnose by deploying the service as a container in a local Docker instance like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "service = Model.deploy(ws, 'test-svc', [model], inference_config, deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOu can then test locally deployed service using the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.run(input_data = json_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then troubleshoot runtime issues by making changes to the scoring file that is referenced in the inference configuration, and reloading the service without redeploying it (something you can only do with a local service):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.reload()\n",
    "print(service.run(input_data = json_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
